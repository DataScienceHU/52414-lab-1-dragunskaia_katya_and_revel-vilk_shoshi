---
title: "52414 - lab 1"
author: "52414"
date: "4/4/2020"
output: html_document
---

# *Lab 1: Basic Data Wrangling*  
<br/><br/>  
  

**Contents**:  

* Q0) [Submission Instructions](#submission-instructions)  
* Q1) [Data Preparation and Manipulation](#data-preparation-and-manipulation)      
* Q2) [Analysis of Daily New Corona Cases and Deaths](#analysis-of-daily-new-corona-cases-and-deaths)    
* Q3) [Preparing and Analyzing the World Bank Data](#preparing-and-analyzing-the-world-bank-data)
* Q4) [Joining the Datasets](#joining-the-datasets)  
* Q5) [Open Question](#open-question)

<br/><br/>
  
  
### Submission Instructions  
  
This lab will be submitted in pairs using GitHub (if you don't have a pair, please contact us).  
Please follow the steps in the  [GitHub-Classroom Lab 1](https://classroom.github.com/g/oSZNtHq4) to create your group's Lab 1 repository.  
**Important: your team's name must be `FamilyName1_Name1_and_FamilyName2_Name2`**.  
You can collaborate with your partner using the git environment; You can either make commits straight to master, or create individual branches (recommended). However, once done, be sure to merge your branches to master - you will be graded using the most recent master version - your last push and merge before the deadline.   
**Please do not open/review other peoples' repositories - we will be notified by GitHub if you do.**

Your final push should include this Rmd file (with your answers) together with the html file that is outputted automatically by knitr when you knit the Rmd. Anything else will be disregarded. In addition, please adhere to the following file format:    
`Lab_2_FamilyName1_Name1_and_FamilyName2_Name2.Rmd/html`      


<br/><br/>
  
The only allowed libraries are the following (**please do not add your own**):
```{r, include=FALSE}
library('tidyverse')
library(data.table)
```  
<br/><br/>

## A Deeper Dive Into John's Hopkins Corona Database         
    
The John's Hopkins Novel Corona Virus (COVID-19) epidemiological data is compiled by the Johns Hopkins University Center for Systems Science and Engineering (JHU CCSE) from various sources. <br>
The dataset contains data since 22nd of January 2020. For the data and more information about it, please visit [here](https://data.humdata.org/dataset/novel-coronavirus-2019-ncov-cases).    
  
In this lab you will pick up where we left in lecture 2 and analyze the Corona cases and deaths data.  

### Q1
### Data Preparation and Manipulation   
(25 points)  

1. We first prepare and aggregate the data.   

a. First, load the `Corona Confirmed Cases Narrow`, the `Corona Confirmed Deaths Narrow`, and the `Corona Confirmed Recovered Narrow` datasets directly from the John's Hopkins website.  
The type of the `Date` variable should be date type. (2 pts)      
b. Create new data-frames named `cases.agg`, `deaths.agg`, and `recovered.agg` which aggregate the `sum` of Corona cases, deaths, and recovered respectively over the different countries' provinces. To do this, aggregate `Value` using only the country and date features, ignoring all other features (similarly to what has been shown in `lecture 2`).  
To achieve the aggregation use the `aggregate` function. In addition, order the data-frame first by Country and then by Date (increasing order). The columns of each of the two resulting data-frames should be `Country.Region, Date, Value`. (5pts)   
c. Repeat (b) using `tidyverse` and the pipe. Show that the outputs from the two methods are the same. (5pts)  
d. Using the last day of March as a reference, create a single stacked bar-plot that visualizes the top 10 countries in terms of their Corona cases, and their respected Corona deaths and recovered cases stacked on top of the current sick people in three different colors (each stack should add up to total cases). Make sure that the first bar shows the number of confirmed Corona sick people (`sick = cases - deaths - recovered`). What is the biggest issue with the information presented in this plot? (13pts)

   
  
**Solution:**  

```{r}
data_con = read.csv(url("https://data.humdata.org/hxlproxy/data/download/time_series_covid19_confirmed_global_narrow.csv?dest=data_edit&filter01=merge&merge-url01=https%3A%2F%2Fdocs.google.com%2Fspreadsheets%2Fd%2Fe%2F2PACX-1vTglKQRXpkKSErDiWG6ycqEth32MY0reMuVGhaslImLjfuLU0EUgyyu2e-3vKDArjqGX7dXEBV8FJ4f%2Fpub%3Fgid%3D1326629740%26single%3Dtrue%26output%3Dcsv&merge-keys01=%23country%2Bname&merge-tags01=%23country%2Bcode%2C%23region%2Bmain%2Bcode%2C%23region%2Bsub%2Bcode%2C%23region%2Bintermediate%2Bcode&filter02=merge&merge-url02=https%3A%2F%2Fdocs.google.com%2Fspreadsheets%2Fd%2Fe%2F2PACX-1vTglKQRXpkKSErDiWG6ycqEth32MY0reMuVGhaslImLjfuLU0EUgyyu2e-3vKDArjqGX7dXEBV8FJ4f%2Fpub%3Fgid%3D398158223%26single%3Dtrue%26output%3Dcsv&merge-keys02=%23adm1%2Bname&merge-tags02=%23country%2Bcode%2C%23region%2Bmain%2Bcode%2C%23region%2Bsub%2Bcode%2C%23region%2Bintermediate%2Bcode&merge-replace02=on&merge-overwrite02=on&filter03=explode&explode-header-att03=date&explode-value-att03=value&filter04=rename&rename-oldtag04=%23affected%2Bdate&rename-newtag04=%23date&rename-header04=Date&filter05=rename&rename-oldtag05=%23affected%2Bvalue&rename-newtag05=%23affected%2Binfected%2Bvalue%2Bnum&rename-header05=Value&filter06=clean&clean-date-tags06=%23date&filter07=sort&sort-tags07=%23date&sort-reverse07=on&filter08=sort&sort-tags08=%23country%2Bname%2C%23adm1%2Bname&tagger-match-all=on&tagger-default-tag=%23affected%2Blabel&tagger-01-header=province%2Fstate&tagger-01-tag=%23adm1%2Bname&tagger-02-header=country%2Fregion&tagger-02-tag=%23country%2Bname&tagger-03-header=lat&tagger-03-tag=%23geo%2Blat&tagger-04-header=long&tagger-04-tag=%23geo%2Blon&header-row=1&url=https%3A%2F%2Fraw.githubusercontent.com%2FCSSEGISandData%2FCOVID-19%2Fmaster%2Fcsse_covid_19_data%2Fcsse_covid_19_time_series%2Ftime_series_covid19_confirmed_global.csv"), comment.char = "#")
data_death = read.csv(url("https://data.humdata.org/hxlproxy/data/download/time_series_covid19_deaths_global_narrow.csv?dest=data_edit&filter01=merge&merge-url01=https%3A%2F%2Fdocs.google.com%2Fspreadsheets%2Fd%2Fe%2F2PACX-1vTglKQRXpkKSErDiWG6ycqEth32MY0reMuVGhaslImLjfuLU0EUgyyu2e-3vKDArjqGX7dXEBV8FJ4f%2Fpub%3Fgid%3D1326629740%26single%3Dtrue%26output%3Dcsv&merge-keys01=%23country%2Bname&merge-tags01=%23country%2Bcode%2C%23region%2Bmain%2Bcode%2C%23region%2Bsub%2Bcode%2C%23region%2Bintermediate%2Bcode&filter02=merge&merge-url02=https%3A%2F%2Fdocs.google.com%2Fspreadsheets%2Fd%2Fe%2F2PACX-1vTglKQRXpkKSErDiWG6ycqEth32MY0reMuVGhaslImLjfuLU0EUgyyu2e-3vKDArjqGX7dXEBV8FJ4f%2Fpub%3Fgid%3D398158223%26single%3Dtrue%26output%3Dcsv&merge-keys02=%23adm1%2Bname&merge-tags02=%23country%2Bcode%2C%23region%2Bmain%2Bcode%2C%23region%2Bsub%2Bcode%2C%23region%2Bintermediate%2Bcode&merge-replace02=on&merge-overwrite02=on&filter03=explode&explode-header-att03=date&explode-value-att03=value&filter04=rename&rename-oldtag04=%23affected%2Bdate&rename-newtag04=%23date&rename-header04=Date&filter05=rename&rename-oldtag05=%23affected%2Bvalue&rename-newtag05=%23affected%2Binfected%2Bvalue%2Bnum&rename-header05=Value&filter06=clean&clean-date-tags06=%23date&filter07=sort&sort-tags07=%23date&sort-reverse07=on&filter08=sort&sort-tags08=%23country%2Bname%2C%23adm1%2Bname&tagger-match-all=on&tagger-default-tag=%23affected%2Blabel&tagger-01-header=province%2Fstate&tagger-01-tag=%23adm1%2Bname&tagger-02-header=country%2Fregion&tagger-02-tag=%23country%2Bname&tagger-03-header=lat&tagger-03-tag=%23geo%2Blat&tagger-04-header=long&tagger-04-tag=%23geo%2Blon&header-row=1&url=https%3A%2F%2Fraw.githubusercontent.com%2FCSSEGISandData%2FCOVID-19%2Fmaster%2Fcsse_covid_19_data%2Fcsse_covid_19_time_series%2Ftime_series_covid19_deaths_global.csv"), comment.char = "#")
data_rec = read.csv (url("https://data.humdata.org/hxlproxy/data/download/time_series_covid19_recovered_global_narrow.csv?dest=data_edit&filter01=merge&merge-url01=https%3A%2F%2Fdocs.google.com%2Fspreadsheets%2Fd%2Fe%2F2PACX-1vTglKQRXpkKSErDiWG6ycqEth32MY0reMuVGhaslImLjfuLU0EUgyyu2e-3vKDArjqGX7dXEBV8FJ4f%2Fpub%3Fgid%3D1326629740%26single%3Dtrue%26output%3Dcsv&merge-keys01=%23country%2Bname&merge-tags01=%23country%2Bcode%2C%23region%2Bmain%2Bcode%2C%23region%2Bsub%2Bcode%2C%23region%2Bintermediate%2Bcode&filter02=merge&merge-url02=https%3A%2F%2Fdocs.google.com%2Fspreadsheets%2Fd%2Fe%2F2PACX-1vTglKQRXpkKSErDiWG6ycqEth32MY0reMuVGhaslImLjfuLU0EUgyyu2e-3vKDArjqGX7dXEBV8FJ4f%2Fpub%3Fgid%3D398158223%26single%3Dtrue%26output%3Dcsv&merge-keys02=%23adm1%2Bname&merge-tags02=%23country%2Bcode%2C%23region%2Bmain%2Bcode%2C%23region%2Bsub%2Bcode%2C%23region%2Bintermediate%2Bcode&merge-replace02=on&merge-overwrite02=on&filter03=explode&explode-header-att03=date&explode-value-att03=value&filter04=rename&rename-oldtag04=%23affected%2Bdate&rename-newtag04=%23date&rename-header04=Date&filter05=rename&rename-oldtag05=%23affected%2Bvalue&rename-newtag05=%23affected%2Binfected%2Bvalue%2Bnum&rename-header05=Value&filter06=clean&clean-date-tags06=%23date&filter07=sort&sort-tags07=%23date&sort-reverse07=on&filter08=sort&sort-tags08=%23country%2Bname%2C%23adm1%2Bname&tagger-match-all=on&tagger-default-tag=%23affected%2Blabel&tagger-01-header=province%2Fstate&tagger-01-tag=%23adm1%2Bname&tagger-02-header=country%2Fregion&tagger-02-tag=%23country%2Bname&tagger-03-header=lat&tagger-03-tag=%23geo%2Blat&tagger-04-header=long&tagger-04-tag=%23geo%2Blon&header-row=1&url=https%3A%2F%2Fraw.githubusercontent.com%2FCSSEGISandData%2FCOVID-19%2Fmaster%2Fcsse_covid_19_data%2Fcsse_covid_19_time_series%2Ftime_series_covid19_recovered_global.csv"), comment.char = "#")
#Change to Date type#
data = list(data_con, data_death, data_rec)
c= c("data_con", "data_death", "data_rec")
for (i in data) {
     i$Date = as.Date(i$Date)}
{print(paste("Class of data in", c, "is", class(i$Date)))}
#Aggregated data-frames using 'aggregate' function#
datasets= list(cases.agg= data_con, death.agg = data_death, recover.agg= data_rec)
agg= lapply(datasets, function(x) {aggregate(Value ~ Country.Region + Date, data = x, FUN= sum) })
#Aggregated data-frames using tidyverse#
datasets.pipe = list(cases.agg = data_con, death.agg = data_death, recover.agg = data_rec)
agg.pipe = lapply(datasets.pipe, function(df){
  df %>% group_by(Country.Region, Date) %>% summarise(Value = sum(Value)) %>% arrange(Date)})
#proof of similarity between the agg.data#
T= all_equal(agg, agg.pipe)
print(paste("aggregation data are similar-", T))
#data on the 31.3.2020#
joined_top =  bind_cols(list(agg[[1]], agg[[2]], agg[[3]])) %>%  filter(Date == "2020-03-31") %>%  select("Country.Region", "Value", "Value1", "Value2") %>%  rename(Cases = Value, Died = Value1, Recovered = Value2) %>% arrange(desc(Cases)) %>% top_n( 10, Cases)
print(joined_top)
#barplot of data on 31.3.2020# 
cases = matrix (c(joined_top$Cases, joined_top$Died, joined_top$Recovered), nrow=10, ncol=3)
rownames(cases)= c(as.character(joined_top$Country.Region))
colnames(cases) = c('Cases','Died','Recovered')
cases.t = t(cases)
{cases.plot = barplot(cases.t[1,], ylab = "Number of Corona cases", xlab= "Countries", main = "The top 10 countries with  confirmed cases in 31 March 2020", width= 0.5,  cex.axis = 0.75, cex.lab= 1, las= 1, col = c("red"), ylim= c(0,200000))
others.plot = barplot(cases.t[2:3,], width= 0.5, cex.axis = 0.75, cex.lab= 1, las= 1, col = c("dark blue", "green"), legend = rownames(cases.t[2:3,]), add = T)}
```

<br/><br/>  

<br/><br/>  

### Q2
### Analysis of Daily New Corona Cases and Deaths  
20 points

The two datasets (Corona Cases and Deaths) register the value of cases and deaths, respectively, as a cumulative sum for each day. In this question we would like to understand the daily differences between consecutive days.     

a. Add a new column named `Diff` to both the `cases.agg` and the `deaths.agg` data-frames. This new column should register the daily `Value` difference for each country. In other words, the `Diff` column shows how many new cases/deaths each country incurs every day. Hint - diff must be per country. (7pts)  
b. Find the top 10 instances of country and date combinations with the greatest absolute number of new daily Corona cases and deaths (separately). Print the result in a descriptive format. (5pts)  
c. In one figure, plot Italy's new daily Corona cases AND deaths as a function of Date. Choose the plot type you think that makes the most sense. (3pts) 
d. Plot the same graph as in (c), but this time plot the number of new cases on the logarithm scale. What can we learn? (5pts)  

  
**Solution:**    

```{r}
#finding the difference between days on agg.data#
top.diff.cases = agg[[1]] %>% group_by(Country.Region) %>%  mutate(diff.cases = Value - lag(Value, default = 0)) %>% select('Country.Region', 'Date', 'diff.cases') %>% ungroup %>% top_n(10, diff.cases)
top.diff.death = agg[[2]] %>% group_by(Country.Region) %>%  mutate(diff.death = Value - lag(Value, default = 0)) %>% select('Country.Region', 'Date', 'diff.death') %>% ungroup %>% top_n(10, diff.death)
#Print the result in a descriptive format#
print(top.diff.cases)
{x= barplot(top.diff.cases$diff.cases, names.arg = top.diff.cases$Date, main= 'Top 10 country & date with the greatest new daily Corona cases', ylab= 'Absolute difference', las=2,  cex.axis = 0.75, cex.names= 0.75, col= rainbow(10))
text(x, 0 ,top.diff.cases$Country.Region, cex=1, pos=3, col='black')
}
print(top.diff.death)
{y= barplot(top.diff.death$diff.death, names.arg = top.diff.death$Date, main= 'Top 10 country & date with the greatest new daily Corona death', ylab= 'Absolute difference', las=2, cex.axis = 0.75, cex.names= 0.75, col= rainbow(10))
text(y, 0 ,top.diff.death$Country.Region, cex=1, pos=3, col='black')
}
#plot Italy’s new daily Corona cases AND deaths as a function of Date#
italy.cases = agg [[1]] %>% filter (Country.Region == 'Italy') %>%  mutate(diff.cases = Value - lag(Value, default = 0)) %>% select('Date', 'diff.cases')  
italy.death = agg[[2]] %>% filter (Country.Region == 'Italy') %>%  mutate(diff.death = Value - lag(Value, default = 0)) %>% select('Date', 'diff.death')
italy.cases$Date = as.Date(italy.cases$Date)
italy.death$Date = as.Date(italy.death$Date)
par(pch=22, col="red") 
par(mfrow=c(1,2)) 
{plot(italy.cases$Date, italy.cases$diff.cases, type ="c", main = 'Italy’s new daily Corona cases', xlab = 'Time', ylab = 'Corona cases', ylim=c(0,7000))
lines(italy.cases$Date, italy.cases$diff.cases, type="l")}
{plot(italy.death$Date, italy.death$diff.death, type ="c", main = 'Italy’s new daily Corona death', xlab = 'Time', ylab = 'Corona cases', ylim=c(0,7000))
lines(italy.death$Date, italy.death$diff.death, type="l")}
```
<br/><br/>
<br/><br/>


### Q3
### Preparing and Analyzing the World Bank Data   
25 points

a. Rename the columns of `eco_data`: `country,S_country,feature,feature_code,Y2018V,Y2019V`. (2pts)  
b. Create a new `eco` data-frame whose dimensions are $266 \times 11$. The first column should include the names of the countries in `eco_data.`   
The rest of the columns should be the features with their respective values in `eco_data` for each country from 2018. Print the head of the new data-frame.(8pts)  
c. Select and rename the following columns: `country` as country, `GDP(US currency)` as GDP, `Population ages 65 and above (% of total population)` as pop65, `Population in the largest city (% of urban population)` as pop_city_ratio, `Population, total` as pop_total columns .  (2pts) 
d. Show a table of the five countries with the highest per capita GDP in 2018.     
Next (considering all countries), plot the % of population over 65 vs. log of GDP per capita in 2018, after excluding the 10% countries with the lowest GDP per capita. Using `lm` and `abline`, add a regression line to the plot. What is your conclusion? (13 pts)  
  
  
  
**Solution:** 

```{r}
#loading the `eco_data`:
eco_data <- read.csv(url("https://raw.githubusercontent.com/DataScienceHU/DataAnalysisR_2020/master/data/economic_data.csv"))

```

### a
Rename columns using function rename
```{r}
names(eco_data) <- c("country", "S_country", "feature", "feature_code", "Y2018V", "Y2019V")
```

### b
Create new data frame eco using dplyr functions such like select, filter and spread. New data frame eco contains 11 columns. Firsr column is a country and others are features. Rows contains values for each country.

```{r}
eco = eco_data %>% select(country, feature, Y2018V) %>% filter(as.character(feature) != "") %>% spread(feature, Y2018V)
```
### c
Rename and select using dplyr function select
```{r}
eco = eco %>% select(country, 
                     GDP = `GDP (current US$)`, 
                     pop_total = `Population, total`,  
                     pop_city_ratio = `Population in the largest city (% of urban population)`, 
                     pop65 = `Population ages 65 and above (% of total population)`)
```

### d
Before we will continue to work with data we will change typeof of collumns with number to make work easily.
```{r, include=FALSE}
eco$GDP <- as.numeric(as.character(eco$GDP))
eco$pop_total <- as.numeric(as.character(eco$pop_total))
eco$pop_city_ratio <- as.numeric(as.character(eco$pop_city_ratio))
eco$pop65 <- as.numeric(as.character(eco$pop65))
```
Import the library tidyverse and dplyr to solve that question <br></br>
1. Using tidyverse find 10 countries with the most GDP
2. Using tidyverse we are looking for new data frame
3. Now we will build the plot and regression line

```{r}
#1
eco_gdp = eco %>% arrange(desc(GDP)) %>% filter(!is.na(GDP)) %>% filter(!is.na(GDP))
head(eco_gdp, n = 10)

#2
eco_gdp_90 = eco_gdp %>% mutate(logGDP_per_capita = log((GDP/pop_total)*100)) %>% head(n = round(length(eco_gdp$country)*0.9))

#3
lm_pop65 <-lm(formula = as.vector(eco_gdp_90$pop65) ~ as.vector(eco_gdp_90$logGDP_per_capita))
plot(x = eco_gdp_90$logGDP_per_capita, y = eco_gdp_90$pop65,
     main = "Q3 (d)", 
     xlab = "logGDP_per_capita",
     ylab = "Population ages 65 and above (% of total population)",
     abline(lm_pop65, col = "red"))
```

<br/><br/>  


### Q4
### Joining the Datasets   
20 points

a. Join the `deaths.agg`, `cases.agg`, and `recovered.agg` into one data-frame called `corona`.(5pts)
b. Join the `corona` and `eco` data-frames in a way that will keep the most information regarding the data (but not full join).   
Make sure that no essential data is thrown away (show this). (3pts)
c. Create new columns of normalized `cases`, `deaths`, and `recovered` so they will show the number of cases per 100,000 people for each country.   
Using the last day of March as a reference, create a single stacked bar plot that visualizes the top 10 countries in terms of normalized Corona cases, and their respected normalized Corona deaths and recovered, as done in Q1.   
how is it different from the graph before normalization? (5pts)
d. Using the last day of March as a reference, create a scatter-plot of normalized deaths and cases vs. `pop65`. Limit the plot to show only countries with 15% or more of `pop65`.   
In addition, color the outliers( pop65>24, norm100K_deaths>15) in that plot in red and add to the plot their country names (7pts)
  
  
**Solution:**   

### a
Joining three datas frame using bind_cols and rename
```{r}
corona = agg[[1]] %>% bind_cols(select(agg[[2]], Value)) %>% bind_cols(select(agg[[3]], Value)) %>% rename(cases = Value, deaths = Value1, recovered = Value2)
```
### b
First we will prepare data frame eco and corona in order to not lose data. In eco, for example, we have "United States" and in corona we have "US", so when we are doing join we are loosing dataabout United States. But in the orginals data frames eco_data and data_con (we can also take data_deaths or data_rec, it is doesn't change anything because all of them have the same countries). We can use that fact to join properly at data. FOr that we will first add to eco and corona column "Code country".
```{r}
#eco
codes_corona = c()
t <- 1
for (i in as.character(eco$country)){
  codes_corona[t] <- as.character(eco_data$S_country[which(i == as.character(eco_data$country))][1])
  t <- t+1
}
eco = eco %>% mutate(`Code country` = codes_corona)
#corona
codes_corona2 = c()
k = 1
for (i in as.character(corona$Country.Region)){
  codes_corona2[k] <- as.character(data_con$ISO.3166.1.Alpha.3.Codes[which(i == as.character(data_con$Country.Region))][1])
  k<- k+1
}
corona = corona %>% mutate(`Code country` = codes_corona2)
```
Now we will user inner join to join eco and corona by Code Country.
```{r}
corona_eco = corona %>% inner_join(eco, by = "Code country") %>% select(Country.Region, Date, cases, deaths, recovered, `Code country`, GDP, pop_total, pop_city_ratio, pop65)
```
To show that we didn't lose any data we will check if countries from corona_eco are the same as countries from eco. After that we will also print head of the data frame.
```{r}
vector_equality <- function(v1, v2){
  for (i in v1){
    check_i <- match(i, v2, nomatch = FALSE)
    if (!check_i){
      return(FALSE)
    }
  }
  return(TRUE)
}
print(vector_equality(unique(corona_eco$Country.Region), unique(corona$Country.Region[which(corona$Country.Region != "Diamond Princess")])))
head(corona_eco)
```
### c
1. Using mutate we creating three new colums.
2. Build par plot similary to Q1. We can see that even if a country occupies a high position in terms of the number of confurmed cases, this does not mean that there is a large number of confurmed cases per 100000. It is depends of total populatin in the country.
```{r}
#1
corona_eco = corona_eco %>% mutate(norm_cases = (cases/pop_total)*100000) %>% mutate(norm_recovered = (recovered/pop_total)*100000) %>% mutate(norm_deaths = (deaths/pop_total)*100000)
#2
corona_eco_march = corona_eco %>% filter(Date == "2020-03-31") %>% arrange(desc(norm_cases)) %>% top_n( 10, norm_cases) %>% select(Country.Region, norm_cases, norm_recovered, norm_deaths)

cases_norm = matrix (c(corona_eco_march$norm_cases, corona_eco_march$norm_deaths, corona_eco_march$norm_recovered), nrow=10, ncol=3)
rownames(cases_norm)= c(as.character(corona_eco_march$Country.Region))
colnames(cases_norm) = c('norm_cases','norm_died','norm_recovered')
cases_norm.t = t(cases_norm)
par(mar = c(11, 11, 11, 11))
{cases_norm.plot = barplot(cases_norm.t[1,], ylab = "Number of Corona sick cases per 100000 people", xlab= "Countries", main = "The top 10 countries with  confirmed cases in 31 March 2020", width= 0.5,  cex.axis = 0.75, cex.lab= 1, las= 1, col = c("red"), ylim= c(0,1000))
others.plot = barplot(cases_norm.t[2:3,], width= 0.5, cex.axis = 0.75, cex.lab= 1, las= 1, col = c("dark blue", "green"), legend = rownames(cases.t[2:3,]), add = T)}
```

### d
First we create data frame to make work easily. Then we build plot using basic graph function.
```{r}
corona_eco_plot = corona_eco %>% filter(pop65 > 15) %>% filter(Date == "2020-03-31")
deaths_num <- which(corona_eco_plot$norm_deaths > 15)
pop65_num <- which(corona_eco_plot$pop65 > 24)
plot(x = corona_eco_plot$norm_cases, y = corona_eco_plot$pop65,
     col = ifelse((corona_eco_plot$pop65 > 24), "red", "black"),
     points(x = corona_eco_plot$norm_deaths, col = ifelse(corona_eco_plot$norm_deaths > 15, "red", "black")),
     xlab = "Cases and death",
     ylab = "Population above 65")
text(corona_eco_plot$pop65[pop65_num], labels = corona_eco_plot$Country.Region[pop65_num])
text(corona_eco_plot$norm_deaths[deaths_num], corona_eco_plot$pop65[deaths_num], labels = corona_eco_plot$Country.Region[deaths_num])
```

<br/><br/>  



### Q5
### Open Question
10 points
  
Write an interesting research question regarding the Corona outbreak and then follow the steps to answer it using tables and plots. You can use the loaded datasets or any other dataset you find as long as you add the data file to your `lab1` repository so it can be loaded directly from a `url` (e.g. the World Bank). This question will be graded based on creativity, originality, and the novelty of the analysis.   
  
**Solution:**   

YOUR SOLUTION HERE.
Use code blocks and markdown to clearly communicate your work.

<br/><br/>  